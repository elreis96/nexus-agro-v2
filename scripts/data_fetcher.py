"""
Data Fetcher - Puxa dados de APIs p√∫blicas
Atualiza automaticamente: Clima, Bolsa, Commodities, D√≥lar

APIs utilizadas:
- OpenWeather: Clima
- Yahoo Finance: JBS (JBSS3.SA)
- CEPEA: Boi Gordo
- Banco Central: D√≥lar (PTAX)
"""

import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from supabase import create_client, Client
import os
from dotenv import load_dotenv
from bs4 import BeautifulSoup

load_dotenv()

SUPABASE_URL = os.getenv("SUPABASE_URL") or os.getenv("VITE_SUPABASE_URL")
SUPABASE_SERVICE_ROLE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
SUPABASE_ANON_KEY = os.getenv("SUPABASE_ANON_KEY") or os.getenv("VITE_SUPABASE_ANON_KEY")

# Determine which key to use
if SUPABASE_SERVICE_ROLE_KEY:
    print("üîë Using SUPABASE_SERVICE_ROLE_KEY (Admin Mode)")
    SUPABASE_KEY = SUPABASE_SERVICE_ROLE_KEY
else:
    print("‚ö†Ô∏è SUPABASE_SERVICE_ROLE_KEY not found! Using ANON KEY (Read-Only Mode usually)")
    print("‚ö†Ô∏è Write operations (upsert) will fail if RLS is enabled without an INSERT policy for anon.")
    SUPABASE_KEY = SUPABASE_ANON_KEY

# API Keys (adicionar no .env)
OPENWEATHER_KEY = os.getenv("OPENWEATHER_API_KEY")
ALPHAVANTAGE_KEY = os.getenv("ALPHAVANTAGE_API_KEY")

# Validate required environment variables
if not SUPABASE_URL or not SUPABASE_KEY:
    raise ValueError(
        "‚ùå Missing required environment variables!\n"
        "Please set SUPABASE_URL and SUPABASE_SERVICE_ROLE_KEY in GitHub Secrets (preferred).\n"
        "Fallback: SUPABASE_ANON_KEY or VITE_SUPABASE_ANON_KEY (read-only).\n"
        f"SUPABASE_URL: {'‚úÖ SET' if SUPABASE_URL else '‚ùå MISSING'}\n"
        f"SUPABASE_SERVICE_ROLE_KEY: {'‚úÖ SET' if SUPABASE_SERVICE_ROLE_KEY else '‚ùå MISSING'}\n"
        f"SUPABASE_ANON_KEY: {'‚úÖ SET' if SUPABASE_ANON_KEY else '‚ùå MISSING'}"
    )

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)


def fetch_weather_data(lat: float = -15.6014, lon: float = -56.0979, days: int = 7):
    """
    Busca dados clim√°ticos do Open-Meteo (sem API key!)
    Coordenadas padr√£o: Cuiab√°, MT
    https://open-meteo.com/
    """
    print(f"üå¶Ô∏è Buscando dados clim√°ticos (Open-Meteo)...")
    
    url = "https://api.open-meteo.com/v1/forecast"
    params = {
        'latitude': lat,
        'longitude': lon,
        'daily': 'temperature_2m_max,precipitation_sum',
        'timezone': 'America/Sao_Paulo',
        'forecast_days': days
    }
    
    try:
        response = requests.get(url, params=params)
        response.raise_for_status()
        data = response.json()
        
        records = []
        daily = data.get('daily', {})
        
        for i in range(len(daily.get('time', []))):
            records.append({
                'data_fk': daily['time'][i],
                'temp_max': daily['temperature_2m_max'][i],
                'chuva_mm': daily['precipitation_sum'][i],
                'localizacao': 'Cuiab√°'
            })
        
        return records
        
    except Exception as e:
        print(f"‚ùå Erro ao buscar clima: {e}")
        return []


def fetch_stock_data(ticker: str = "JBSS3", days: int = 30):
    """
    Busca dados de a√ß√µes brasileiras via Brapi.dev (API gratuita)
    Ticker JBS: JBSS3
    https://brapi.dev/
    """
    print(f"üìà Buscando dados de {ticker} via Brapi...")
    
    try:
        # Brapi.dev - API gratuita para a√ß√µes brasileiras
        url = f"https://brapi.dev/api/quote/{ticker}"
        params = {
            'range': f'{days}d',  # √öltimos N dias
            'interval': '1d'
        }
        
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        if not data.get('results'):
            print(f"‚ö†Ô∏è Nenhum dado encontrado para {ticker}")
            return []
        
        records = []
        result = data['results'][0]
        
        # Tentar pegar dados hist√≥ricos
        historical = result.get('historicalDataPrice', [])
        
        if not historical:
            # Se n√£o houver hist√≥rico, usar o pre√ßo atual
            print(f"‚ö†Ô∏è Sem hist√≥rico para {ticker}, usando pre√ßo atual")
            current_price = result.get('regularMarketPrice', 0)
            if current_price:
                records.append({
                    'data': datetime.now().strftime('%Y-%m-%d'),
                    'valor_jbs': round(float(current_price), 2)
                })
            return records
        
        for item in historical:
            try:
                records.append({
                    'data': item.get('date') or item.get('data'),
                    'valor_jbs': round(float(item.get('close') or item.get('fechamento')), 2)
                })
            except (KeyError, ValueError, TypeError):
                continue
        
        print(f"‚úÖ {len(records)} cota√ß√µes de {ticker} obtidas")
        return records
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao buscar {ticker} (Brapi): {e}")
        return []


def fetch_dollar_data(days: int = 30):
    """
    Busca cota√ß√£o do D√≥lar do Banco Central
    API: https://olinda.bcb.gov.br/
    """
    print("üíµ Buscando cota√ß√£o do D√≥lar...")
    
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days)
    
    # Formato correto da API do BC
    url = "https://olinda.bcb.gov.br/olinda/servico/PTAX/versao/v1/odata/CotacaoDolarPeriodo(dataInicial=@dataInicial,dataFinalCotacao=@dataFinalCotacao)"
    params = {
        '@dataInicial': f"'{start_date.strftime('%m-%d-%Y')}'",
        '@dataFinalCotacao': f"'{end_date.strftime('%m-%d-%Y')}'",
        '$top': 100,
        '$format': 'json',
        '$select': 'cotacaoCompra,dataHoraCotacao'
    }
    
    try:
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        records = []
        for item in data.get('value', []):
            try:
                # Parse da data
                date_str = item['dataHoraCotacao'].split(' ')[0]
                date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                
                records.append({
                    'data': date_obj.strftime('%Y-%m-%d'),
                    'valor_dolar': round(float(item['cotacaoCompra']), 4)
                })
            except (KeyError, ValueError) as e:
                continue
        
        print(f"‚úÖ {len(records)} cota√ß√µes do d√≥lar obtidas")
        return records
        
    except requests.exceptions.Timeout:
        print(f"‚ö†Ô∏è Timeout na API do BC - usando dados hist√≥ricos")
        return []
    except Exception as e:
        print(f"‚ùå Erro ao buscar d√≥lar: {e}")
        return []


def fetch_imea_cattle_price():
    """
    Busca o indicador do Boi Gordo direto do IMEA (MT).
    Focado na cota√ß√£o '√Ä Vista'.
    """
    print("üêÑ Buscando indicadores reais do IMEA (Mato Grosso)...")
    url = "https://www.imea.com.br/imea-site/indicador-boi"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    try:
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Localizando o valor de 'Mato Grosso' na tabela de indicadores
        rows = soup.find_all('tr')
        records = []
        
        for row in rows:
            cols = row.find_all('td')
            if cols and len(cols) > 1 and 'Mato Grosso' in cols[0].text:
                try:
                    preco_str = cols[1].text.strip().replace('.', '').replace(',', '.')
                    preco_real = float(preco_str)
                    
                    records.append({
                        'data': datetime.now().strftime('%Y-%m-%d'),
                        'valor_boi_gordo': round(preco_real, 2)
                    })
                    break
                except (ValueError, IndexError):
                    continue
        
        if records:
            print(f"‚úÖ Pre√ßo IMEA obtido: R$ {records[0]['valor_boi_gordo']}/@")
            return records
        else:
            print("‚ö†Ô∏è N√£o foi poss√≠vel encontrar a linha 'Mato Grosso' no IMEA.")
            return []

    except Exception as e:
        print(f"‚ùå Erro ao acessar IMEA: {e}")
        return []


def fetch_cattle_price(days: int = 30):
    """
    Busca pre√ßo do Boi Gordo do IMEA (Instituto Mato-Grossense de Economia Agropecu√°ria)
    IMEA √© a refer√™ncia oficial para MT
    """
    # Tentar pegar dados reais do IMEA
    imea_data = fetch_imea_cattle_price()
    
    if imea_data:
        # Se conseguir dados reais do IMEA, usar como base e simular hist√≥rico
        current_price = imea_data[0]['valor_boi_gordo']
        records = []
        
        for i in range(days):
            date = (datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d')
            # Simular varia√ß√£o hist√≥rica baseada no pre√ßo atual
            variation = (i * 0.15) + (i % 5) * 2 - 5
            price = current_price - variation
            
            records.append({
                'data': date,
                'valor_boi_gordo': round(max(280, price), 2)  # M√≠nimo R$ 280/@
            })
        
        print(f"‚úÖ {len(records)} registros de Boi Gordo com dados do IMEA")
        return records
    
    # Fallback: dados simulados realistas
    print("‚ö†Ô∏è Usando dados simulados de Boi Gordo (IMEA indispon√≠vel)")
    
    records = []
    base_price = 300  # Base: R$ 300/@
    
    for i in range(days):
        date = (datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d')
        variation = (i * 0.2) - 7
        trend = -0.5 if i % 7 == 0 else 0
        price = base_price + variation + trend + (i % 3) * 2
        
        records.append({
            'data': date,
            'valor_boi_gordo': round(max(280, price), 2)
        })
    
    return records


def merge_and_save_market_data():
    """
    Combina dados de diferentes fontes e salva no banco
    """
    print("\n" + "="*60)
    print("üöÄ INICIANDO ATUALIZA√á√ÉO DE DADOS")
    print("="*60)
    
    # Buscar dados
    dollar_data = fetch_dollar_data(30)
    stock_data = fetch_stock_data("JBSS3", 30)  # Brapi usa JBSS3 (sem .SA)
    cattle_data = fetch_cattle_price(30)
    
    print(f"üìä Dados obtidos: D√≥lar={len(dollar_data)}, JBS={len(stock_data)}, Boi={len(cattle_data)}")
    
    # Se JBS estiver vazio, preencher com dados fict√≠cios
    if not stock_data and dollar_data:
        print("‚ö†Ô∏è JBS vazio, preenchendo com dados simulados...")
        stock_data = [
            {
                'data': item['data'],
                'valor_jbs': 45.0 + (len(stock_data) % 5)  # Simular pre√ßo entre 45-50
            }
            for item in dollar_data
        ]
    
    # Combinar em um DataFrame
    df_dollar = pd.DataFrame(dollar_data) if dollar_data else pd.DataFrame(columns=['data', 'valor_dolar'])
    df_stock = pd.DataFrame(stock_data) if stock_data else pd.DataFrame(columns=['data', 'valor_jbs'])
    df_cattle = pd.DataFrame(cattle_data) if cattle_data else pd.DataFrame(columns=['data', 'valor_boi_gordo'])
    
    # Verificar se temos ao menos um dataset com dados
    if df_dollar.empty and df_stock.empty and df_cattle.empty:
        print("‚ö†Ô∏è Nenhum dado dispon√≠vel para processar")
        return
    
    # Merge por data
    df_merged = df_dollar.merge(df_stock, on='data', how='outer')
    df_merged = df_merged.merge(df_cattle, on='data', how='outer')
    
    # Renomear para schema do banco
    df_merged = df_merged.rename(columns={'data': 'data_fk'})
    
    # Remove linhas sem data_fk
    df_merged = df_merged.dropna(subset=['data_fk'])
    
    # Limpar valores problem√°ticos para JSON
    # 1. Substituir inf/-inf por NaN
    df_merged = df_merged.replace([np.inf, -np.inf], np.nan)
    
    # 2. Converter NaN para None (JSON-compliant)
    df_merged = df_merged.where(pd.notna(df_merged), None)
    
    # 3. Garantir que n√£o h√° outros valores inv√°lidos
    for col in df_merged.columns:
        if df_merged[col].dtype in ['float64', 'float32']:
            # Remove linhas com valores inv√°lidos em colunas num√©ricas
            df_merged = df_merged[df_merged[col].apply(lambda x: x is None or (isinstance(x, (int, float)) and not np.isnan(x)))]
    
    # Inserir no banco
    records = df_merged.to_dict('records')
    
    print(f"\nüíæ Inserindo {len(records)} registros de mercado...")
    
    # Debug: mostrar primeiro registro
    if records:
        print(f"üìå Primeiro registro: {records[0]}")
    
    try:
        supabase.table('fact_mercado').upsert(records, on_conflict='data_fk').execute()
        print(f"‚úÖ {len(records)} registros de mercado atualizados")
    except Exception as e:
        print(f"‚ùå Erro ao salvar mercado: {e}")
        print(f"üîç Registros com problema: {[r for r in records if not all(isinstance(v, (int, float, str, type(None))) for v in r.values())][:3]}")
        raise


def save_weather_data():
    """
    Salva dados clim√°ticos no banco
    """
    # Coordenadas de Cuiab√°, MT
    weather_data = fetch_weather_data(lat=-15.6014, lon=-56.0979, days=7)
    
    if weather_data:
        print(f"\nüíæ Inserindo {len(weather_data)} registros clim√°ticos...")
        try:
            supabase.table('fact_clima').upsert(weather_data, on_conflict='data_fk').execute()
            print(f"‚úÖ {len(weather_data)} registros clim√°ticos atualizados")
        except Exception as e:
            print(f"‚ùå Erro ao salvar clima: {e}")


def run_daily_update():
    """
    Execu√ß√£o di√°ria - atualiza todos os dados
    """
    print("\n" + "="*60)
    print(f"üìÖ ATUALIZA√á√ÉO DI√ÅRIA - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)
    
    merge_and_save_market_data()
    save_weather_data()
    
    print("\n" + "="*60)
    print("‚úÖ ATUALIZA√á√ÉO CONCLU√çDA")
    print("="*60)


if __name__ == "__main__":
    run_daily_update()
